# Author: 潘维吉
# Version 1.0.0
# Description: 自定义构建VLLM大模型引擎版本和CUDA版本

FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive

RUN apt update && apt install -y \
    python3 python3-pip git && \
    ln -s /usr/bin/python3 /usr/bin/python

RUN pip install --upgrade pip

# 安装 CUDA 12.4 对应 torch
#RUN pip install torch==2.2.2+cu124 torchvision==0.17.2+cu124 \
#    --index-url https://download.pytorch.org/whl/cu124 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com

# 安装 vllm
RUN pip install vllm==0.15.1 -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com

WORKDIR /workspace


# 镜像构建 并上传到镜像仓库
# docker build -t panweiji/vllm:latest -f /my/Dockerfile.vllm . --no-cache
# docker push panweiji/vllm:latest

# 启动运行
#docker run -d --restart=always -p 8008:8000 --name deepseek-vllm --gpus all --shm-size=1g -v /my/deepseek/cache:/root/.cache/huggingface -e HF_ENDPOINT=https://hf-mirror.com  \
#panweiji/vllm:latest python -m vllm.entrypoints.openai.api_server --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B --trust-remote-code --host 0.0.0.0 --port 8000 --gpu-memory-utilization 0.5 --dtype half --max-model-len 8192