# Author: 潘维吉
# Description: 云原生K8S部署应用yaml核心通用配置文件 不同项目传入动态传参复用  同时部署Deployment与Service服务

apiVersion: apps/v1
kind: Deployment
metadata:
  name: {APP_NAME}-deployment
  namespace: {K8S_NAMESPACE}
  labels:
    app: {APP_COMMON_NAME}     # Service的selector可以通过metadata labels来筛选，多个不同pod通过一个Service访问打相同的labels

spec:
  replicas: {K8S_POD_REPLICAS}       # Pod节点默认副本数
  selector:
    matchLabels:
      app: {APP_COMMON_NAME}

  template:
    metadata:
      labels:
        app: {APP_COMMON_NAME}
#      annotations:
#        prometheus.io/scrape: "true"                # 让prometheus自动发现
#        prometheus.io/path: /actuator/prometheus    # /metric路径是集成内提供的 Prometheus 监控接口 或利用 exporter 服务来为 Prometheus 提供指标数据
#        prometheus.io/port: "{CONTAINER_PORT}"      # /metric接口的端口

    spec:
      #privileged: true  # 允许特权模式的Pod
      hostPID: true  # 使用宿主机命名空间 方便容器获取宿主机所有进程 解决多个docker节点RocketMQ重复消费消息等问题 默认false
      containers:
        - name: {APP_COMMON_NAME}
          image: {IMAGE_URL}:{IMAGE_TAG}
          imagePullPolicy: Always  # 获取镜像的策略 Always表示总是下载最新镜像 IfNotPresent表示优先使用本地镜像，否则下载镜像，Never表示仅使用本地镜像
          resources: # 对Pod的资源限制机制 合理设置CPU 内存 防止CPU打满 内存溢出 导致整个服务器宕机
            requests: # 资源请求 调度器根据值选择满足资源的节点 保证应用启动运行的最小资源 低于要求资源等待部署
              cpu: 200m  # cpu请求 容器启动的初始可用数量
              memory: 200Mi # 内存请求 容器启动的初始可用数量 不能大于limits设置值
              ephemeral-storage: "1Gi"  # 容器需要的最小临时存储量
            limits:
              # m是千分之一  100m是0.1个CPU  限制最大cpu防止资源溢出 导致整个集群全部不可用
              cpu: "{MAX_CPU_SIZE}"
              # 设置memory应用最大使用内存 限制防止雪崩现象导致其它服务不可用 不支持小数点形式的设置 K8S默认对占用高资源会有驱逐Evicted机制
              memory: "{MAX_MEMORY_SIZE}i"
              ephemeral-storage: "10Gi"  # 限制容器可以使用的最大临时存储量
          ports:
            - containerPort: {CONTAINER_PORT}
              protocol: TCP  # 容器级协议 HTTP/1.1 + HTTP/2
#            - containerPort: {CONTAINER_PORT}
#              protocol: UDP  # 容器级协议 HTTP/3 QUIC
          env:
            - name: TZ
              value: Asia/Shanghai
            - name: SPRING_PROFILES_ACTIVE
              value: {SPRING_PROFILE}
            - name: JAVA_OPTS # 生产服务器将-Xms和-Xmx设置为相同值是强烈推荐的黄金法则 主要好处是避免内存动态调整导致性能抖动 垃圾回收行为更可预测
              value: "-Xms512m -XX:MaxMetaspaceSize=256m {JAVA_OPTS_XMX}" # K8s中不会自动解析ENTRYPOINT环境变量 导致配置无效 最大堆内存 如 -Xmx1024m
            - name: EXTEND_PORT
              value: "{CONTAINER_PORT}"
            - name: HOST_NAME
              value: $(KUBERNETES_SERVICE_HOST)
          # 通过 YAML 文件中的 command 和 args 字段来指定启动命令和参数。可以覆盖或补充 Dockerfile中定义的 ENTRYPOINT和CMD启动命令
          # command: [ "java"] # 这里覆盖了 ENTRYPOINT 中的第一个元素（可选）
          # args: ["-jar"]  # 覆盖或追加ENTRYPOINT参数  非空参数 否则报错
          # 日志限制 如:  args: ["--log-driver=json-file", "--log-opt=max-size=100m", "--log-opt=max-file=2"]
          # 优雅停机  Pod被删除时，状态置为 Terminating 。 kube-proxy 更新转发规则，将 Pod 从 service 的 endpoint 列表中摘除掉，新的流量不再转发到该 Pod
          lifecycle:
            preStop:
              exec:
                command: ["sleep", "3"]  # 等待 kube-proxy 完成规则同步再开始停止容器内进程 仅保留必要的最小等待时间
          # startupProbe（启动探针）检测容器是否完成启动 在 startupProbe 成功之前，其他探针（readinessProbe 和 livenessProbe）不会启动
          startupProbe:
            httpGet:
              path: {CUSTOM_HEALTH_CHECK_PATH}
              port: {DEFAULT_CONTAINER_PORT}
            initialDelaySeconds: 0     # 探针在容器启动后的多少秒才开始执行  如GraalVM启动毫秒级
            periodSeconds: 2           # 探针执行频率。默认是10秒，最小1秒
            timeoutSeconds: 1          # 探测超时时间。默认1秒，最小1秒
            successThreshold: 1        # 连续探测1次成功表示成功
            failureThreshold: 80       # 允许最多多少次失败
          # readinessProbe（就绪探测）服务可用性进行检测 确保容器准备好处理请求后才被加入负载均衡
          readinessProbe: #  Pod 未就绪时，它会从服务负载均衡器中删除   Readiness探针在容器的整个生命周期内运行在容器上
            #tcpSocket: # TCP 端口连通性探测 轻量级，无需应用层协议支持
            #port: 8080  # 探测目标端口
            httpGet:  # 任何大于或等于 200 且小于 400 的代码都表示成功。任何其他代码表示失败
              path: {CUSTOM_HEALTH_CHECK_PATH}
              port: {DEFAULT_CONTAINER_PORT}
            initialDelaySeconds: 1   # 探针在容器启动后的多少秒才开始执行
            periodSeconds: 10        # 探针执行频率。默认是10秒，最小1秒
            timeoutSeconds: 1        # 探测超时时间。默认1秒，最小1秒
            successThreshold: 1      # 连续探测1次成功表示成功
            failureThreshold: 3      # 探测成功后，最少连续探测失败多少次才被认定为失败。默认是3。最小值是1
          # livenessProbe（存活探测） 对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器
          livenessProbe:
            httpGet:
              path: {CUSTOM_HEALTH_CHECK_PATH}
              port: {DEFAULT_CONTAINER_PORT}
            initialDelaySeconds: 1     #容器启动后到第一次探测开始的等待时间
            periodSeconds: 30
            timeoutSeconds: 2
            successThreshold: 1       # 连续探测1次成功表示成功
            failureThreshold: 3
          #securityContext: # 容器安全级别配置增强
            #readOnlyRootFilesystem: true      # 将容器根文件系统设为只读 防止恶意写入关键目录 可能导致容器无法启动
            #allowPrivilegeEscalation: false   # 禁止进程通过 sudo 等方式提高权限 防止病毒控制 可能影响业务
      terminationGracePeriodSeconds: {K8S_GRACE_PERIOD_SECONDS}  # 优雅终止宽限期 默认30秒 减少时间可缩短Pod销毁等待时 根据是否有健康绪探测变化值大小
      restartPolicy: Always         # Pod的重启策略 Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Never表示不再重启该Pod
      # 新特性topologySpreadConstraints分布约束代替affinity亲和度 实现均匀部署pod到不同的node 拓扑分布约束 在K8s v1.18版本进入beta阶段默认启用 参考文档： https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/topology-spread-constraints/
      topologySpreadConstraints:    # 配置一个拓扑分布约束
        - maxSkew: 1                            # Pod可能被不均匀分布的程度
          topologyKey: kubernetes.io/hostname   # 按照节点来分散 Pod
          whenUnsatisfiable: ScheduleAnyway     # 当无法满足约束条件时的行为。可选值为 DoNotSchedule不调度 或 ScheduleAnyway 无论如何都调度
          labelSelector:
            matchLabels:
              app: {APP_COMMON_NAME}
      # affinity: # 使用工作负载反亲和特性，让Pod之间尽量“互斥”，能尽量均匀的分布在各node节点上  参考文档： https://support.huaweicloud.com/cce_faq/cce_faq_00260.html
#      affinity: # 处理反亲和导致第一次部署后重复部署的冲突问题 滚动部署旧pod存在导致
#        podAntiAffinity:
#          preferredDuringSchedulingIgnoredDuringExecution:
#            - weight: 100
#              podAffinityTerm:
#                labelSelector:
#                  matchExpressions:
#                    - key: app            # node节点标签方式 kubectl get nodes --show-labels 与 kubectl label nodes <your-node-name> nodeLabelName=node1
#                      operator: In        # NotIn 和 DoesNotExist 可用来实现节点反亲和性行为。 你也可以使用节点污点 将 Pod 从特定节点上驱逐
#                      values:
#                        - {APP_COMMON_NAME}
#                namespaces:
#                  - {K8S_NAMESPACE}
#                topologyKey: kubernetes.io/hostname         # pod不会调度到同一节点 在节点上起作用
      # 私有镜像拉取密钥配置   参考文档：https://kubernetes.io/docs/concepts/containers/images/#creating-a-secret-with-a-docker-config
      # kubectl create secret docker-registry k8s-docker-registry-secret --docker-server=registry.cn-qingdao.aliyuncs.com  --docker-username=2000160180 --docker-password=panweiji@2022 --docker-email=406798106@qq.com --namespace=default
      imagePullSecrets:
        - name: {K8S_IMAGE_PULL_SECRETS}
  # K8S部署更新策略
  strategy:
    type: RollingUpdate  # 滚动更新 “RollingUpdate”是默认值   Recreate类型在创建新 Pod 之前，所有现有的 Pod 会被杀死
    rollingUpdate:  # 滚动更新速率控制
      maxSurge: 30%        # 允许同时创建的最大新 Pod 数量 默认值25% 期望副本数最大比例或最大值  值越小，越能保证服务稳定，更新越平滑  可为整数（比如 3），也可是百分百，向上取整
      maxUnavailable: 50%  # 允许同时销毁的旧 Pod 数量 默认值25% 最大不可用副本数最大比例或最大值  值调的越大，副本更新速度越快
  revisionHistoryLimit: 1  # 保留可回滚历史版本数量 减少值可磁盘占用

---

apiVersion: v1
kind: Service

metadata:
  name: {APP_COMMON_NAME}-service
  namespace: {K8S_NAMESPACE}
  labels:
    app: {APP_COMMON_NAME}-service
#  annotations:
#    prometheus.io/scrape: "true"                # 让prometheus自动发现
#    prometheus.io/path: /actuator/prometheus    # /metric路径是集成内提供的 Prometheus 监控接口 或利用 exporter 服务来为 Prometheus 提供指标数据
#    prometheus.io/port: "{CONTAINER_PORT}"      # /metric接口的端口

spec:
  type: LoadBalancer                   # 规格类型ClusterIP、NodePort、LoadBalancer、Ingress实现Pod外网访问和负载均衡 LoadBalancer不支持同时多个协议
  selector:
    app: {APP_COMMON_NAME}             # 通过Pod的labels指定Pod 建立关联  Service的selector可以通过metadata labels来筛选，多个不同pod通过一个Service访问打相同的labels
  ports:
    - name: {APP_COMMON_NAME}
      port: {HOST_PORT}                # 指定Service接收请求的端口
      targetPort: {CONTAINER_PORT}     # 请求转发的端口 容器内部端口
      #nodePort: {HOST_PORT}           # NodePort类型端口区间 30000–32767 不指定端口，系统将分配一个随机端口
      protocol: TCP                    # 定义通信协议 UDP通讯协议 支持HTTP/3 + QUIC

#  Session保持  Ingress的解决方案:  https://www.modb.pro/db/210201
#  sessionAffinity: ClientIP            # 集群Session共享设置为 "ClientIP" 注意只适用NodePort类型 （默认值是 "None"值 Service向后台Pod转发规则是轮询），来基于客户端的IP地址选择固定会话Pod关联
#  sessionAffinityConfig:
#    clientIP:
#      timeoutSeconds: 7200            # 保持时间 秒